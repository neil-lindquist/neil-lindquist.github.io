---
layout: page
title: Curriculum Vitae
meta-description: The Curriculum Vitae of Neil Lindquist
---

<h2 class="visible-print-block">
  Neil Lindquist
</h2>

<p class="visible-print-block">
  NeilLindquist5@gmail.com
</p>

# Education

Ph.D. student in Computer Science, University of Tennesee,
* Advised by Dr. Jack Dongarra

B.A. *magna cum laude* in Math and Computer Science, Saint John's University, 2019

* Advised by Dr. Mike Heroux
* Thesis: [Reducing Memory Access Latencies using Data Compression in Sparse, Iterative Linear Solvers](https://github.com/neil-lindquist/Undergrad-Thesis/blob/master/thesis.pdf)

# Honors and Awards

Top 500 Fellowship, University of Tennessee (August 2019 - Present)

Pi Mu Epsilon Mathematics Honor Society (inducted May 2019)

Phi Beta Kappa Honors Society (inducted April 2019)

Eagle Scout (awarded June 2014)

# Publications

[Accepted] **N. Lindquist**, P. Luszczek, and J. Dongarra, “Improving the Performance of the GMRES method using Mixed-Precision Techniques,” presented at the Smokey Mountains Conference, 2020.
* Tested the use of a mix of single and double precisions to improve the performance of GMRES while retaining double precision accuracy.

A. Abdelfattah, et al., "A Survey of Numerical Methods Utilizing Mixed Precision Arithmetic", 2020, arXiv:2007.06674
* [arXiv](https://arxiv.org/abs/2007.06674)

**N. Lindquist**, “Replicated Computational Results (RCR) Report for ‘Code Generation for Generally Mapped Finite Elements,’” ACM Trans. Math. Softw., vol. 45, no. 4, pp. 42:1–42:7, Dec. 2019.
* A replication of the computational results in the named paper by Robert C. Kirby and Lawrence Mitchell
* [Download](https://dl.acm.org/authorize?N690907)


# Presentations

[Improve the Performance of GMRES using Mixed Precision](/files/2020-02-13-SIAM_PP20-slides.pdf)
* 2020 SIAM Conference of Parallel Processing for Scientific Computing

[Reducing Memory Access Latencies using Data Compression in Sparse, Iterative Linear Solvers](/files/2019-04-12-PMEslides.pdf)
 * 2019 CSB/SJU Pi Mu Epsilon Conference

[Obtaining Performance from a Julia-Implementation of Trilinos Data Librairies](https://www.pathlms.com/siam/courses/10878/sections/14368/video_presentations/127457)
 * 2019 SIAM Conference on Computational Science and Engineering


# Research Experience

Graduate Research Assistant - [Innovative Computing Laboratory](https://icl.utk.edu/) at the University of Tennesee under Dr. Jack Dongarra (July 2019 through the present)
* Experimenting with use of a mix of double and single floating point precision in GMRES, a sparse, iterative linear solver.
* Experimenting with using Random Butterfly Transforms to replace pivoting in LU factorization for the SLATE distributed, dense linear algebra library.

Graduate Research Assistant - [Global Computing Laboratory](https://globalcomputing.group/) at the University of Tennesee under Dr. Michela Taufer (August 2019 through February 2020)
* Contributed to a machine learning based workflow for classification of protein structural properties from XFEL diffraction patterns.

Research Assistant - [Collegeville Group](http://github.com/Collegeville) at Saint John's University under Dr. Mike Heroux (May 2017 through May 2019)
* Explored the use of data compression to improve the performance of Conjugate Gradient, a sparse, iterative linear solver.
* Tested the effect on performance of using Julia, a high level programming language, to implement distributed, sparse linear algebra codes.
